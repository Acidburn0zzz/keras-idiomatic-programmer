{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idiomatic Programmer Code Labs\n",
    "\n",
    "## Code Labs #3 - Get Familiar with Data Curation\n",
    "\n",
    "## Prerequistes:\n",
    "\n",
    "    1. Familiar with Python\n",
    "    2. Completed Handbook 2/Part 13: Data Curation\n",
    "\n",
    "## Objectives:\n",
    "\n",
    "    1. Preprocessing a builtin dataset (cifar-10)\n",
    "    2. Train dataset for a few epochs\n",
    "    3. Use same model architecture for larger number of classes (cifar-100)\n",
    "    4. Use image augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's import the builtin datasets for:\n",
    "\n",
    "    CIFAR-10: 32x32 images, 10 classes, 60000 images (6000 per class)\n",
    "    CIFAR-100: 32x32 images, 100 classes, 60000 images (600 per class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10, cifar100\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "Let's start with a function that will create our model using a simple CNN architecture, as follows:\n",
    "\n",
    "*Stem Group*\n",
    "\n",
    "*Convolutional Blocks*\n",
    "\n",
    "*Classifier*/\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization, GlobalAveragePooling2D, Dense\n",
    "\n",
    "def convNet(input_shape, nclasses):\n",
    "    def stem(inputs, nb_filters):\n",
    "        ''' Stem Convolutional Group '''\n",
    "\n",
    "        # Use two 3x3 convolutional layers (no downsampling, strides=1)\n",
    "        x = Conv2D(nb_filters, (3, 3), strides=1, padding='same', activation='relu')(inputs)\n",
    "        x = Conv2D(nb_filters, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "\n",
    "        # Downsample with Max Pooling\n",
    "        x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        return x\n",
    "\n",
    "    def conv_block(x, nb_filters):\n",
    "        ''' Convolutional Block '''\n",
    "\n",
    "        # A 3x3 and 1x1 factorization of two 3x3 convolutional layers\n",
    "        x = Conv2D(nb_filters, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "        x = Conv2D(nb_filters, (1, 1), strides=1, padding='same', activation='relu')(x)\n",
    "\n",
    "        # Downsample with Max Pooling\n",
    "        x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')(x)\n",
    "        return x\n",
    "    \n",
    "    def classifier(x, nclasses):\n",
    "        ''' Classifier '''\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dense(nclasses, activation='softmax')(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    # Input and Stem Group\n",
    "    inputs = Input(input_shape)\n",
    "    x = stem(inputs, 32)\n",
    "\n",
    "    # Two Convolutional Blocks, each doubles the number of filters\n",
    "    for nb_filters in [64, 128]:\n",
    "        x = conv_block(x, nb_filters)\n",
    "\n",
    "    outputs = classifier(x, nclasses)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    # HERE\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test  = to_categorical(y_test)\n",
    "\n",
    "# HERE\n",
    "x_train = (x_train / 255.0).astype(np.float32)\n",
    "x_test  = (x_test  / 255.0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "\n",
    "```\n",
    "Total params: 140,970\n",
    "Trainable params: 140,970\n",
    "Non-trainable params: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/google/home/aferlitsch/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/google/home/aferlitsch/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        4160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         16512     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 140,970\n",
      "Trainable params: 140,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = convNet((32, 32, 3), 10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/google/home/aferlitsch/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "45000/45000 [==============================] - 48s 1ms/step - loss: 1.7638 - acc: 0.3267 - val_loss: 1.5418 - val_acc: 0.4306\n",
      "Epoch 2/3\n",
      "45000/45000 [==============================] - 47s 1ms/step - loss: 1.3431 - acc: 0.5015 - val_loss: 1.1677 - val_acc: 0.5768\n",
      "Epoch 3/3\n",
      "45000/45000 [==============================] - 47s 1ms/step - loss: 1.1374 - acc: 0.5857 - val_loss: 1.0620 - val_acc: 0.6208\n",
      "10000/10000 [==============================] - 2s 249us/step\n",
      "[1.076918307876587, 0.612]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=3, validation_split=0.1, verbose=1)\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test  = to_categorical(y_test)\n",
    "\n",
    "# HERE\n",
    "mean = np.mean(x_train)\n",
    "std  = np.std(x_train)\n",
    "x_train = ((x_train - mean) / std).astype(np.float32)\n",
    "x_test  = ((x_test - mean) / std).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "\n",
    "```\n",
    "Total params: 152,580\n",
    "Trainable params: 152,580\n",
    "Non-trainable params: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        4160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         16512     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 152,580\n",
      "Trainable params: 152,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = convNet((32, 32, 3), 100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "45000/45000 [==============================] - 47s 1ms/step - loss: 4.0642 - acc: 0.0650 - val_loss: 3.7644 - val_acc: 0.1038\n",
      "Epoch 2/3\n",
      "45000/45000 [==============================] - 47s 1ms/step - loss: 3.5169 - acc: 0.1448 - val_loss: 3.3557 - val_acc: 0.1798\n",
      "Epoch 3/3\n",
      "45000/45000 [==============================] - 47s 1ms/step - loss: 3.1390 - acc: 0.2152 - val_loss: 3.0367 - val_acc: 0.2392\n",
      "10000/10000 [==============================] - 3s 252us/step\n",
      "[3.006009662628174, 0.2443]\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=3, validation_split=0.1, verbose=1)\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation with ImageDataGenerator\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1407/1406 [==============================] - 49s 35ms/step - loss: 4.2184 - acc: 0.0469 - val_loss: 3.9444 - val_acc: 0.0862\n",
      "Epoch 2/3\n",
      "1407/1406 [==============================] - 49s 35ms/step - loss: 3.7382 - acc: 0.1111 - val_loss: 3.6149 - val_acc: 0.1352\n",
      "Epoch 3/3\n",
      "1407/1406 [==============================] - 49s 35ms/step - loss: 3.4762 - acc: 0.1540 - val_loss: 3.3742 - val_acc: 0.1686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2a300be7b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(vertical_flip=True, horizontal_flip=True, rotation_range=30)\n",
    "\n",
    "#HERE - Validation Split\n",
    "pivot = int(len(x_train) * 0.9)\n",
    "x_val = x_train[pivot:]\n",
    "y_val = y_train[pivot:]\n",
    "x_train = x_train[:pivot]\n",
    "y_train = y_train[:pivot]\n",
    "\n",
    "model = convNet((32, 32, 3), 100)\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=32), epochs=3, steps_per_epoch=len(x_train)/32, \n",
    "                    validation_data=(x_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
