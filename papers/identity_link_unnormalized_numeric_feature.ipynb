{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Identity Links Deep Neural Networks\n",
    "\n",
    "Shallow Deep neural networks are the 'defacto' model for structured data consisting only of numeric data (e.g., sensor measurements).\n",
    "\n",
    "When numeric data columns are not normalized within the same range, we find that many times a deep neural network will either not converge, or overfit to the training data. We will demonstrate that a shallow deep neural network can be trained to converge without overfitting on non-normalized numeric data by adding an identity link from the input vector to each shallow layer.\n",
    "\n",
    "We observe from this technique the following:\n",
    "\n",
    "    1. Introduces regularization into the model (preventing overfitting).\n",
    "    2. Adds stability to the slope of the valuation loss/accuracy with non-normalized data.\n",
    "    \n",
    "While the identity link adds some parameters, we add it as a concatenation vector operation. This is a fast operation, and only adds a nominal number of parameters at each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "In this notebook, we use two well-known numeric only datasets: 'iris' and 'wine' for demonstration. Both datasets consists of numeric data only with three output classes. \n",
    "\n",
    "### Iris Dataset\n",
    "\n",
    "This dataset consists of 150 examples for three output classes (50 each). The data consists of 4 numeric columns.\n",
    "\n",
    "See (UCI Machine Learning Repository for more details)[https://archive.ics.uci.edu/ml/datasets/iris]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "Y_iris = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Dataset\n",
    "\n",
    "This dataset consists of 178 examples for three output classes (~60 each). The data consists of 13 numeric columns.\n",
    "\n",
    "See (UCI Machine Learning Repository for more details)[https://archive.ics.uci.edu/ml/datasets/wine]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()\n",
    "X_wine = wine.data\n",
    "Y_wine = wine.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "For both datasets, we will use the same shallow deep model, with the only difference being the input vector:\n",
    "\n",
    "        input layer : 10 node dense layer\n",
    "        hidden layer: 10 node dense layer\n",
    "        output layer: 3 node dense layer\n",
    "        \n",
    "We will train using non-normalized data on two versions of the model for each dataset. In the first version, we will train w/o the identity linkand then with the identity link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Model\n",
    "\n",
    "    iris_model  : model w/o identity link\n",
    "    iris_modelx : model with identity link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Concatenate\n",
    "\n",
    "inputs = Input(shape=(4,))\n",
    "x = Dense(10, activation='relu')(inputs)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "outputs = Dense(3, activation='softmax')(x)\n",
    "iris_model = Model(inputs, outputs)\n",
    "iris_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "iris_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 10)           50          input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 14)           0           input_12[0][0]                   \n",
      "                                                                 dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 10)           150         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 14)           0           input_12[0][0]                   \n",
      "                                                                 dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 3)            45          concatenate_11[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 245\n",
      "Trainable params: 245\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(4,))\n",
    "x = Dense(10, activation='relu')(inputs)\n",
    "x = Concatenate()([inputs, x])\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = Concatenate()([inputs, x])\n",
    "outputs = Dense(3, activation='softmax')(x)\n",
    "iris_modelx = Model(inputs, outputs)\n",
    "iris_modelx.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "iris_modelx.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Model\n",
    "\n",
    "    wine_model  : model w/o identity link\n",
    "    wine_modelx : model with identity link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 283\n",
      "Trainable params: 283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(13,))\n",
    "x = Dense(10, activation='relu')(inputs)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "outputs = Dense(3, activation='softmax')(x)\n",
    "wine_model = Model(inputs, outputs)\n",
    "wine_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "wine_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 10)           140         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 23)           0           input_14[0][0]                   \n",
      "                                                                 dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 10)           240         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 23)           0           input_14[0][0]                   \n",
      "                                                                 dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 3)            72          concatenate_13[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 452\n",
      "Trainable params: 452\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(13,))\n",
    "x = Dense(10, activation='relu')(inputs)\n",
    "x = Concatenate()([inputs, x])\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = Concatenate()([inputs, x])\n",
    "outputs = Dense(3, activation='softmax')(x)\n",
    "wine_modelx = Model(inputs, outputs)\n",
    "wine_modelx.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "wine_modelx.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Each traing session will train for 30 epochs for stocastic gradient descent (batch=1).\n",
    "\n",
    "### Iris w/o identity Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 0s 2ms/sample - loss: 2.5674 - acc: 0.1667 - val_loss: 0.4745 - val_acc: 1.0000\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 729us/sample - loss: 0.8648 - acc: 0.7500 - val_loss: 1.0285 - val_acc: 0.0000e+00\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 723us/sample - loss: 0.6682 - acc: 0.8500 - val_loss: 0.8579 - val_acc: 0.0000e+00\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 736us/sample - loss: 0.5293 - acc: 0.8833 - val_loss: 0.7385 - val_acc: 0.3667\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 717us/sample - loss: 0.4477 - acc: 0.8917 - val_loss: 0.9266 - val_acc: 0.0000e+00\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 797us/sample - loss: 0.3962 - acc: 0.8667 - val_loss: 0.6592 - val_acc: 0.6000\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 759us/sample - loss: 0.3554 - acc: 0.8833 - val_loss: 0.6822 - val_acc: 0.5000\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 736us/sample - loss: 0.3214 - acc: 0.8833 - val_loss: 0.6614 - val_acc: 0.6000\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 732us/sample - loss: 0.2927 - acc: 0.9167 - val_loss: 1.2172 - val_acc: 0.0000e+00\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 728us/sample - loss: 0.2803 - acc: 0.8917 - val_loss: 1.0967 - val_acc: 0.0000e+00\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 735us/sample - loss: 0.2623 - acc: 0.9083 - val_loss: 0.6980 - val_acc: 0.4667\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 727us/sample - loss: 0.2467 - acc: 0.9333 - val_loss: 0.7001 - val_acc: 0.5000\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 720us/sample - loss: 0.2299 - acc: 0.9250 - val_loss: 0.3518 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 726us/sample - loss: 0.2251 - acc: 0.9417 - val_loss: 0.3542 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 734us/sample - loss: 0.2107 - acc: 0.9583 - val_loss: 1.0502 - val_acc: 0.0667\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 745us/sample - loss: 0.1917 - acc: 0.9333 - val_loss: 0.4662 - val_acc: 0.8667\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 737us/sample - loss: 0.1897 - acc: 0.9667 - val_loss: 0.6423 - val_acc: 0.6000\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 745us/sample - loss: 0.1907 - acc: 0.9333 - val_loss: 0.3208 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 726us/sample - loss: 0.1647 - acc: 0.9667 - val_loss: 0.6210 - val_acc: 0.6333\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 762us/sample - loss: 0.1541 - acc: 0.9583 - val_loss: 0.3066 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 750us/sample - loss: 0.1514 - acc: 0.9750 - val_loss: 0.7411 - val_acc: 0.4667\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 734us/sample - loss: 0.1415 - acc: 0.9750 - val_loss: 0.5507 - val_acc: 0.7000\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 738us/sample - loss: 0.1387 - acc: 0.9583 - val_loss: 0.3047 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 829us/sample - loss: 0.1313 - acc: 0.9833 - val_loss: 0.5632 - val_acc: 0.6333\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 917us/sample - loss: 0.1327 - acc: 0.9750 - val_loss: 1.0557 - val_acc: 0.3333\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 866us/sample - loss: 0.1241 - acc: 0.9750 - val_loss: 0.3461 - val_acc: 0.9000\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 831us/sample - loss: 0.1085 - acc: 0.9917 - val_loss: 0.7585 - val_acc: 0.5000\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 863us/sample - loss: 0.1143 - acc: 0.9667 - val_loss: 0.7597 - val_acc: 0.5000\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 857us/sample - loss: 0.1102 - acc: 0.9750 - val_loss: 0.4153 - val_acc: 0.7333\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 826us/sample - loss: 0.1010 - acc: 0.9750 - val_loss: 0.4704 - val_acc: 0.7333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9c897b0f0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " iris_model.fit(X_iris, Y_iris, epochs=30, batch_size=1, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 0s 2ms/sample - loss: 1.2748 - acc: 0.3000 - val_loss: 1.3369 - val_acc: 0.0000e+00\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 840us/sample - loss: 0.7657 - acc: 0.7750 - val_loss: 0.9735 - val_acc: 0.0000e+00\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 771us/sample - loss: 0.5576 - acc: 0.8417 - val_loss: 1.0936 - val_acc: 0.0000e+00\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 750us/sample - loss: 0.4395 - acc: 0.8500 - val_loss: 1.3736 - val_acc: 0.0000e+00\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 772us/sample - loss: 0.3848 - acc: 0.8667 - val_loss: 1.2372 - val_acc: 0.0000e+00\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 796us/sample - loss: 0.3519 - acc: 0.8583 - val_loss: 0.5310 - val_acc: 0.9333\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 783us/sample - loss: 0.3227 - acc: 0.9000 - val_loss: 0.8014 - val_acc: 0.3000\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 783us/sample - loss: 0.3049 - acc: 0.8667 - val_loss: 0.6657 - val_acc: 0.5333\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 875us/sample - loss: 0.2685 - acc: 0.9250 - val_loss: 1.0809 - val_acc: 0.0000e+00\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 833us/sample - loss: 0.2607 - acc: 0.8833 - val_loss: 0.4263 - val_acc: 0.9667\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 807us/sample - loss: 0.2414 - acc: 0.9250 - val_loss: 0.3830 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 781us/sample - loss: 0.2236 - acc: 0.9583 - val_loss: 0.5780 - val_acc: 0.7333\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 780us/sample - loss: 0.2018 - acc: 0.9833 - val_loss: 0.5227 - val_acc: 0.7333\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 775us/sample - loss: 0.1902 - acc: 0.9833 - val_loss: 0.7534 - val_acc: 0.4667\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 773us/sample - loss: 0.1792 - acc: 0.9500 - val_loss: 0.4719 - val_acc: 0.8000\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 789us/sample - loss: 0.1676 - acc: 0.9583 - val_loss: 0.3840 - val_acc: 0.9000\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1521 - acc: 0.9667 - val_loss: 0.5740 - val_acc: 0.7333\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 837us/sample - loss: 0.1480 - acc: 0.9917 - val_loss: 0.5881 - val_acc: 0.7000\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 774us/sample - loss: 0.1405 - acc: 0.9750 - val_loss: 0.6462 - val_acc: 0.5333\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 783us/sample - loss: 0.1335 - acc: 0.9750 - val_loss: 0.5211 - val_acc: 0.7333\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 775us/sample - loss: 0.1266 - acc: 0.9833 - val_loss: 0.3310 - val_acc: 0.9000\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 774us/sample - loss: 0.1197 - acc: 0.9917 - val_loss: 0.3678 - val_acc: 0.9000\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 773us/sample - loss: 0.1089 - acc: 0.9750 - val_loss: 0.4291 - val_acc: 0.7667\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 766us/sample - loss: 0.1096 - acc: 0.9833 - val_loss: 0.4357 - val_acc: 0.7667\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 775us/sample - loss: 0.1084 - acc: 0.9750 - val_loss: 0.3283 - val_acc: 0.9000\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 773us/sample - loss: 0.1036 - acc: 0.9833 - val_loss: 0.4716 - val_acc: 0.7333\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 785us/sample - loss: 0.0917 - acc: 0.9833 - val_loss: 0.5870 - val_acc: 0.7000\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 793us/sample - loss: 0.0878 - acc: 0.9833 - val_loss: 0.8175 - val_acc: 0.5000\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 774us/sample - loss: 0.1030 - acc: 0.9583 - val_loss: 0.3710 - val_acc: 0.8000\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 788us/sample - loss: 0.0934 - acc: 0.9833 - val_loss: 0.2257 - val_acc: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9e931a7b8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_modelx.fit(X_iris, Y_iris, epochs=30, batch_size=1, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/30\n",
      "142/142 [==============================] - 0s 2ms/sample - loss: 55.8233 - acc: 0.5282 - val_loss: 79.0462 - val_acc: 0.0000e+00\n",
      "Epoch 2/30\n",
      "142/142 [==============================] - 0s 785us/sample - loss: 4.7335 - acc: 0.7817 - val_loss: 23.1832 - val_acc: 0.0000e+00\n",
      "Epoch 3/30\n",
      "142/142 [==============================] - 0s 762us/sample - loss: 1.9010 - acc: 0.7676 - val_loss: 8.2698 - val_acc: 0.0278\n",
      "Epoch 4/30\n",
      "142/142 [==============================] - 0s 756us/sample - loss: 1.6688 - acc: 0.7254 - val_loss: 7.8907 - val_acc: 0.0000e+00\n",
      "Epoch 5/30\n",
      "142/142 [==============================] - 0s 755us/sample - loss: 1.5295 - acc: 0.7254 - val_loss: 5.2020 - val_acc: 0.2500\n",
      "Epoch 6/30\n",
      "142/142 [==============================] - 0s 755us/sample - loss: 1.2432 - acc: 0.7606 - val_loss: 2.5615 - val_acc: 0.0000e+00\n",
      "Epoch 7/30\n",
      "142/142 [==============================] - 0s 760us/sample - loss: 1.3083 - acc: 0.7465 - val_loss: 5.7311 - val_acc: 0.0000e+00\n",
      "Epoch 8/30\n",
      "142/142 [==============================] - 0s 758us/sample - loss: 1.1706 - acc: 0.7887 - val_loss: 2.4794 - val_acc: 0.0000e+00\n",
      "Epoch 9/30\n",
      "142/142 [==============================] - 0s 759us/sample - loss: 1.3017 - acc: 0.8169 - val_loss: 0.7177 - val_acc: 0.6944\n",
      "Epoch 10/30\n",
      "142/142 [==============================] - 0s 759us/sample - loss: 1.0995 - acc: 0.7254 - val_loss: 3.3826 - val_acc: 0.0000e+00\n",
      "Epoch 11/30\n",
      "142/142 [==============================] - 0s 795us/sample - loss: 1.1897 - acc: 0.8028 - val_loss: 2.7451 - val_acc: 0.3889\n",
      "Epoch 12/30\n",
      "142/142 [==============================] - 0s 838us/sample - loss: 1.0748 - acc: 0.7465 - val_loss: 4.8173 - val_acc: 0.0000e+00\n",
      "Epoch 13/30\n",
      "142/142 [==============================] - 0s 802us/sample - loss: 1.1160 - acc: 0.7676 - val_loss: 4.6676 - val_acc: 0.0000e+00\n",
      "Epoch 14/30\n",
      "142/142 [==============================] - 0s 752us/sample - loss: 1.0769 - acc: 0.7746 - val_loss: 3.0818 - val_acc: 0.0000e+00\n",
      "Epoch 15/30\n",
      "142/142 [==============================] - 0s 753us/sample - loss: 0.9563 - acc: 0.7606 - val_loss: 1.8671 - val_acc: 0.0278\n",
      "Epoch 16/30\n",
      "142/142 [==============================] - 0s 777us/sample - loss: 1.0488 - acc: 0.7324 - val_loss: 4.5186 - val_acc: 0.0000e+00\n",
      "Epoch 17/30\n",
      "142/142 [==============================] - 0s 786us/sample - loss: 1.0894 - acc: 0.7606 - val_loss: 2.9043 - val_acc: 0.0000e+00\n",
      "Epoch 18/30\n",
      "142/142 [==============================] - 0s 815us/sample - loss: 0.8827 - acc: 0.7676 - val_loss: 2.5189 - val_acc: 0.0000e+00\n",
      "Epoch 19/30\n",
      "142/142 [==============================] - 0s 753us/sample - loss: 1.0102 - acc: 0.7817 - val_loss: 3.6014 - val_acc: 0.0000e+00\n",
      "Epoch 20/30\n",
      "142/142 [==============================] - 0s 764us/sample - loss: 0.9594 - acc: 0.7254 - val_loss: 1.7969 - val_acc: 0.2222\n",
      "Epoch 21/30\n",
      "142/142 [==============================] - 0s 741us/sample - loss: 0.8387 - acc: 0.7606 - val_loss: 1.1649 - val_acc: 0.3889\n",
      "Epoch 22/30\n",
      "142/142 [==============================] - 0s 750us/sample - loss: 0.7743 - acc: 0.7817 - val_loss: 1.5627 - val_acc: 0.1111\n",
      "Epoch 23/30\n",
      "142/142 [==============================] - 0s 745us/sample - loss: 0.8248 - acc: 0.7817 - val_loss: 2.5516 - val_acc: 0.0000e+00\n",
      "Epoch 24/30\n",
      "142/142 [==============================] - 0s 736us/sample - loss: 0.8727 - acc: 0.7324 - val_loss: 3.7648 - val_acc: 0.0000e+00\n",
      "Epoch 25/30\n",
      "142/142 [==============================] - 0s 754us/sample - loss: 0.6503 - acc: 0.8169 - val_loss: 1.6692 - val_acc: 0.3056\n",
      "Epoch 26/30\n",
      "142/142 [==============================] - 0s 753us/sample - loss: 0.7595 - acc: 0.8239 - val_loss: 1.7831 - val_acc: 0.0000e+00\n",
      "Epoch 27/30\n",
      "142/142 [==============================] - 0s 755us/sample - loss: 0.6687 - acc: 0.7676 - val_loss: 1.0058 - val_acc: 0.3611\n",
      "Epoch 28/30\n",
      "142/142 [==============================] - 0s 750us/sample - loss: 0.6804 - acc: 0.8028 - val_loss: 1.3597 - val_acc: 0.2500\n",
      "Epoch 29/30\n",
      "142/142 [==============================] - 0s 750us/sample - loss: 0.6856 - acc: 0.8380 - val_loss: 2.7118 - val_acc: 0.0000e+00\n",
      "Epoch 30/30\n",
      "142/142 [==============================] - 0s 752us/sample - loss: 0.6404 - acc: 0.8239 - val_loss: 1.7729 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9e91d8198>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_model.fit(X_wine, Y_wine, epochs=30, batch_size=1, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples, validate on 18 samples\n",
      "Epoch 1/30\n",
      "160/160 [==============================] - 0s 2ms/sample - loss: 79.8944 - acc: 0.1937 - val_loss: 9.2984 - val_acc: 0.0000e+00\n",
      "Epoch 2/30\n",
      "160/160 [==============================] - 0s 750us/sample - loss: 6.9795 - acc: 0.3750 - val_loss: 24.9290 - val_acc: 0.0000e+00\n",
      "Epoch 3/30\n",
      "160/160 [==============================] - 0s 747us/sample - loss: 3.9265 - acc: 0.5688 - val_loss: 1.7274 - val_acc: 0.5000\n",
      "Epoch 4/30\n",
      "160/160 [==============================] - 0s 744us/sample - loss: 2.4195 - acc: 0.6313 - val_loss: 0.8600 - val_acc: 0.6111\n",
      "Epoch 5/30\n",
      "160/160 [==============================] - 0s 751us/sample - loss: 1.7023 - acc: 0.6812 - val_loss: 2.2329 - val_acc: 0.1111\n",
      "Epoch 6/30\n",
      "160/160 [==============================] - 0s 738us/sample - loss: 1.4491 - acc: 0.6812 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 7/30\n",
      "160/160 [==============================] - 0s 738us/sample - loss: 1.4903 - acc: 0.6812 - val_loss: 2.6650 - val_acc: 0.0000e+00\n",
      "Epoch 8/30\n",
      "160/160 [==============================] - 0s 726us/sample - loss: 1.3046 - acc: 0.6938 - val_loss: 2.4751 - val_acc: 0.0000e+00\n",
      "Epoch 9/30\n",
      "160/160 [==============================] - 0s 737us/sample - loss: 1.5419 - acc: 0.7063 - val_loss: 6.0211 - val_acc: 0.0000e+00\n",
      "Epoch 10/30\n",
      "160/160 [==============================] - 0s 745us/sample - loss: 1.6252 - acc: 0.7375 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 11/30\n",
      "160/160 [==============================] - 0s 765us/sample - loss: 1.4526 - acc: 0.7375 - val_loss: 3.3293 - val_acc: 0.0000e+00\n",
      "Epoch 12/30\n",
      "160/160 [==============================] - 0s 768us/sample - loss: 2.0619 - acc: 0.6687 - val_loss: 2.2001 - val_acc: 0.1667\n",
      "Epoch 13/30\n",
      "160/160 [==============================] - 0s 772us/sample - loss: 0.9144 - acc: 0.7875 - val_loss: 5.6418 - val_acc: 0.0000e+00\n",
      "Epoch 14/30\n",
      "160/160 [==============================] - 0s 742us/sample - loss: 1.1112 - acc: 0.8188 - val_loss: 0.1303 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "160/160 [==============================] - 0s 772us/sample - loss: 0.9566 - acc: 0.7812 - val_loss: 0.4149 - val_acc: 0.8333\n",
      "Epoch 16/30\n",
      "160/160 [==============================] - 0s 745us/sample - loss: 0.8774 - acc: 0.8250 - val_loss: 0.1106 - val_acc: 1.0000\n",
      "Epoch 17/30\n",
      "160/160 [==============================] - 0s 749us/sample - loss: 0.8340 - acc: 0.8313 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "160/160 [==============================] - 0s 731us/sample - loss: 0.8017 - acc: 0.8188 - val_loss: 4.5968 - val_acc: 0.0000e+00\n",
      "Epoch 19/30\n",
      "160/160 [==============================] - 0s 741us/sample - loss: 0.5651 - acc: 0.8875 - val_loss: 0.0718 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "160/160 [==============================] - 0s 742us/sample - loss: 2.1695 - acc: 0.7937 - val_loss: 6.2200e-05 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "160/160 [==============================] - 0s 736us/sample - loss: 1.3800 - acc: 0.7812 - val_loss: 0.8171 - val_acc: 0.6111\n",
      "Epoch 22/30\n",
      "160/160 [==============================] - 0s 747us/sample - loss: 0.7844 - acc: 0.8125 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "160/160 [==============================] - 0s 741us/sample - loss: 0.9332 - acc: 0.8687 - val_loss: 2.8266 - val_acc: 0.5000\n",
      "Epoch 24/30\n",
      "160/160 [==============================] - 0s 746us/sample - loss: 1.0944 - acc: 0.8000 - val_loss: 0.1207 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "160/160 [==============================] - 0s 742us/sample - loss: 0.6155 - acc: 0.8875 - val_loss: 0.3208 - val_acc: 0.8333\n",
      "Epoch 26/30\n",
      "160/160 [==============================] - 0s 742us/sample - loss: 1.3112 - acc: 0.7937 - val_loss: 1.2929e-04 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "160/160 [==============================] - 0s 738us/sample - loss: 0.9384 - acc: 0.8687 - val_loss: 0.5610 - val_acc: 0.7778\n",
      "Epoch 28/30\n",
      "160/160 [==============================] - 0s 732us/sample - loss: 0.6945 - acc: 0.8500 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "160/160 [==============================] - 0s 735us/sample - loss: 0.7816 - acc: 0.8750 - val_loss: 0.0227 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "160/160 [==============================] - 0s 752us/sample - loss: 0.6322 - acc: 0.8813 - val_loss: 0.0040 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9e9470f98>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_modelx.fit(X, Y, epochs=30, batch_size=1, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
